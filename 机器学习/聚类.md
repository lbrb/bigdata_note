# 聚类

- 聚类的一个作用是做降维，n个维度降到分类的维度

聚类是根据相似度来判断的，类内的相似度大，类间的相似度小

### 相似度衡量指标

- 欧式距离（几何空间）
- 余弦相似度（自然预研处理）
- 杰卡德相似度（集合数据）
- 皮尔逊相关系数

### K-Means算法

- 选择初始的K个类别中心
- 计算所有样本到k个类别中心的距离，距离哪个类近就属于哪个类
- 计算每个类的均值（中值）作为新的类别中心
- 重复2-3步骤，直到类别中心不变为止

### K-Means++算法

初始的聚类中心之间的相互距离要尽可能的远

1. 从输入的数据点集合中随机选择一个点作为第一个聚类中心
2. 对于数据集中的每一个点x，计算它与最近聚类中心(指已选择的聚类中心)的距离D(x)
3. 选择一个新的数据点作为新的聚类中心，选择的原则是：D(x)较大的点，被选取作为聚类中心的概率较大
4. 重复2和3直到k个聚类中心被选出来
5. 利用这k个初始的聚类中心来运行标准的k-means算法

### Mini-batch k-Means算法

计算新的u时，仅使用该簇中的部分数据

### 目标函数

目标函数是平方差

K-means对样本是有要求的，是K个符合高斯模型的样本集

k-means因为是多个高斯分布，是多极值问题，初值的不同选择可能造成不同的结果，一些机器学习库，会提供做几次的参数

### 聚类的衡量指标

- 均一性

- 完整性

### 层次聚类

- 最小距离
- 最大距离
- 平均距离

### 密度聚类

只要样本点的密度大于某阈值，则将该样本添加到最近的簇中，可以排除异常值

### DBSCAN算法

两个参数，r，m

数据量太大不适应

1. 如果一个点p的e-邻域包含多于m个对象，则创建一个p作为核心对象的新簇；
2. 寻找并合并核心对象直接密度可达的对象；
3. 没有新点可以更新簇时，算法结束；

